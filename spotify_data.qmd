---
execute:
  echo: false
  message: false
  warning: false
---

# Spotify Feature Analysis

One of my favorite hobbies is listening to music. Not just through headphones or in the car, but listening to live music and experiencing all of the energy that comes with live performances. Some time ago I found out that R had a package, `spotifyr` @spotify_r, that was a wrapper for getting track audio features from Spotify's API. I started exploring the functionality of the package along with a few projects people had done (see )

https://d2l.ai/index.html

```{r preliminaries}
library(tidyverse)
library(GGally)
library(corrplot)
library(ggfortify)
library(gridExtra)
library(cowplot) 
library(knitr)
library(viridis)
library(hrbrthemes)
library(lubridate)
library(plotly)
library(recipes)
library(caret)
library(rsample)
library(randomForest)
library(ranger)
library(cluster)     # provides bottom-up clustering support
library(factoextra)  # support for plotting of clusters

library(dbscan)
# RData file with all objects already saved down for speed purposes
load("all_data_saved.RData")
```

```{r objects-to-save}
#| eval: false
# s.dat.1 <- readRDS("data/songs_no_transform.rds")
# s.dat.2 <- readRDS("data/songs_log_transform.rds")
# metal.nonmetal <- readRDS("data/metal_nonmetal_split.rds")
# songs <- readRDS("data/songs_final.rds")

data_saver <- c("s.dat.1", "s.dat.2", "songs", "metal.nonmetal")
save(list = data_saver, file = "all_data_saved.RData")

```

```{r data-cleaning}
#| eval: false
# change the three categorical variables into factors
songs <- read.csv('data/genre_songs_8.csv')
songs$key <- as.factor(songs$key)
songs$mode <- as.factor(songs$mode)


#shorten name and turn to date object (lubridate)
songs <- songs %>% 
  mutate(release_date = as.Date(track.album.release_date))

# dropping the release_Date column for missing dates
songs <- songs %>% 
  select(-release_date)

# renaming columns to make analysis easier
songs <- songs %>% 
  rename(duration = duration_ms,
         genre = playlist_genre,
         subgenre = playlist_subgenre)

# genre should be categorical not character
songs <- songs %>% 
  mutate(genre = as.factor(genre))

# remove duplicate songs based on track.id
songs <- songs %>% 
  distinct(track.id, .keep_all = TRUE)

# convert from ms to minutes
songs$duration <- songs$duration / 60000

songs <- songs %>% 
  filter(is.finite(acousticness))

# create predictor subsets
s.dat.1 <- songs
# saveRDS(songs, "songs_no_transform.rds")

# transform the variables with logarithm
songs[which(songs$acousticness==0),]$acousticness <- .0000001
songs <- songs %>%
  mutate(acousticness = log(acousticness))

songs[which(songs$instrumentalness==0),]$instrumentalness <- .0000001
songs <- songs %>%
  mutate(instrumentalness = log(instrumentalness))

songs[which(songs$speechiness==0),]$speechiness <- .0000001
songs <- songs %>%
  mutate(speechiness = log(speechiness))


s.dat.2 <- songs
# saveRDS(songs, "songs_log_transform.rds")

# remove long duration songs
songs <- songs %>% 
  filter(duration < 10)

# remove loudness > 0
songs <- songs %>% 
  filter(loudness <= 0) %>% 
  mutate(loudness = loudness * -1)

# make all negative numerical values positive
songs <- songs %>% 
  mutate(speechiness = speechiness * -1)

songs <- songs %>% 
  mutate(instrumentalness = instrumentalness * -1)

songs <- songs %>% 
  mutate(acousticness = acousticness * -1)

# dummy variable for metal and nonmetal
songs <- songs %>% 
  mutate(metal = factor(case_when(genre == "metal" ~ 1,
                           TRUE ~ 0)))

# saveRDS(songs, "songs_final.rds")

# split the data into a smaller dataset with only metal and nonmetal labels
# will be downsampling from the nonmetal dataset to the max number of metal songs
metal.songs <- songs %>% 
  filter(genre == "metal")
nonmetal.songs <- songs %>% 
  filter(genre != "metal") %>% 
  sample_n(nrow(metal.songs))

metal.nonmetal <- rbind(metal.songs, nonmetal.songs)
metal.nonmetal <- metal.nonmetal %>% 
  select(-genre)

# saveRDS(metal.sample, "metal_nonmetal_split.rds")

```

```{r missing-data-visual}
#| eval: false
songs %>%
  is.na() %>%
  reshape2::melt() %>%
  ggplot(aes(Var2, Var1, fill=value)) + 
    geom_raster() + 
    coord_flip() +
    scale_y_continuous(NULL, expand = c(0, 0)) +
    scale_fill_grey(name = "", 
                    labels = c("Present", 
                               "Missing")) +
    xlab("Observation") +
    theme(axis.text.y  = element_text(size = 4))
```

```{r variable-separation}
cat_predictors <- c("genre", "key", "mode")
# cat_used <- select(songs, cat_predictors)


#separate out the 9 numerical variables
num_predictors <- c('danceability', 'energy','loudness','speechiness',
                    'acousticness', 'instrumentalness', 'valence','tempo','duration','liveness')

num_used <- select(songs, num_predictors)
predictors <- c(cat_predictors, num_predictors)

feature_names <- c(names(num_used))

```

First things first, I needed data before I could analyze. I utilized some function calls to pull down data from Spotify's API with a few predetermined genres of music. From here, I read this in to R to begin exploring what data I had. There were some issues.

```{r density-plot-1}
#| eval: false
p1 <- s.dat.1 %>%
  select(c('genre', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value)) +
  geom_density(aes(color = genre), alpha = 0.9) +
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Spotify Audio Feature Density - by Genre',
       x = '', y = 'density') +
  theme(axis.text.y = element_blank()) + 
  scale_color_brewer(palette = 'Set1')
ggsave("density_plot_1.png", p1)
```

![](figs/density_plot_1.png)

Acousticness seems drastically skewed to the right and concentrated right around 0. Instrumentalness and Loudness seem to also have similar problems. Duration **seems** fine, but there's a large tail that extends to almost an hour and a half. There needs to be some cleaning done here to get the data into an easily analyzed format.

```{r density-plot-2}
#| eval: false
p2 <- s.dat.2 %>%
  select(c('genre', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value)) +
  geom_density(aes(color = genre), alpha = 0.9) +
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Spotify Audio Feature Density - by Genre',
       x = '', y = 'density') +
  theme(axis.text.y = element_blank()) + 
  scale_color_brewer(palette = 'Set1')
ggsave("density_plot_2.png", p2)

```

![](figs/density_plot_2.png)

This seems a bit better but duration still looks skewed so lets see why there is such a long tail to the right. First I'll start by looking at how many songs have a duration longer than 10 minutes.

```{r duration-analysis}

s.dat.1 %>% 
  filter(duration > 10) %>% summarise(Count = n())
```

There are only 99 songs with a duration longer than 10 minutes and the overall dataset has 36K songs. For the purposes of this analysis it's best to take these out as they don't represent the majority of the data.

One more look at the density plot before we start taking apart the features and looking towards prediction/classification.

```{r density-plot-3}
#| eval: false
p3 <- songs %>%
  select(c('genre', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value)) +
  geom_density(aes(color = genre), alpha = 0.9) +
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Spotify Audio Feature Density - by Genre',
       x = '', y = 'density') +
  theme(axis.text.y = element_blank()) + 
  scale_color_brewer(palette = 'Set1')
ggsave("density_plot_3.png", p3)

```

![](figs/density_plot_3.png)

# Exploratory Data Analysis

```{r genre-counts}
# get a count of tracks in all genres
songs %>% 
  group_by(genre) %>% 
  summarise(Count = n()) %>% 
  kable(caption = "Distribution of Song Counts by Genre",
        col.names = c("Genre", "Count"))
```

```{r pairs-plot-all}
#| eval: false
p4 <- songs %>%
  sample_n(100) %>%
  ggpairs(feature_names)

ggsave("pairs_plot_1.png", p4)
# s = cor(songs[,c("speechiness", "acousticness")])
# corrplot(s, method = "color")
```

![](figs/pairs_plot_1.png)


```{r danceability-hist}
#| eval: false
# songs %>% 
#   ggplot(aes(x = danceability, color = playlist_genre)) +
#   geom_histogram(bins = 50) +
#   facet_wrap(~ playlist_genre)

songs %>% 
  ggplot(aes(x = danceability, fill = genre, color = genre)) +
  geom_histogram(alpha = 0.6) + 
  scale_fill_viridis(discrete = TRUE) +
  scale_color_viridis(discrete = TRUE) +
  # theme_ipsum() +
  # theme(
  #   legend.position = "none",
  #   panel.spacing = unit(0.1, "lines"),
  #   strip.text.x = element_text(size = 8)
  # )+
  facet_wrap(~ genre)
```

# Data Separation for Modeling

```{r split1}
# split with all genres
split1 <- initial_split(songs[feature_names], prop = .7) # samples index 

train1 <- training(split1)
test1 <- testing(split1)

```

```{r}
# split with metal and nonmetal
split2 <- initial_split(metal.nonmetal, prop = .7) # samples index 

train2 <- training(split2)
test2 <- testing(split2)
```

```{r}
#| eval: false
rf <- randomForest(genre~., data=train1, importance=TRUE) 
print(rf)
```

```{r}
#| eval: false
p1 <- predict(rf, test1)
confusionMatrix(p1, test1$genre)
```

```{r}
#| eval: false
plot(rf)
```

```{r}
#| eval: false
varImpPlot(rf,
           sort = T,
           n.var = 10,
           main = "Top 10 - Variable Importance")
```

```{r}
#| eval: false
rf <- randomForest(metal~., data=train2, importance=TRUE) 
print(rf)
```

```{r}
#| eval: false
p2 <- predict(rf, test2)
confusionMatrix(p2, test2$metal)
```

```{r}
#| eval: false
plot(rf)
```

```{r}
#| eval: false
varImpPlot(rf,
           sort = T,
           n.var = 10,
           main = "Top 10 - Variable Importance")
```

# Finding Separation in Metal and Nonmetal Genres

Performing classification analysis on 8 genres leads to poor accuracy. While each song has many features, the differences may be too small to meaningfully differentiate one genre from another. However, there are still genres that we could certainly recognize as being starkly different. Metal happens to be my favorite genre, but I do listen to country from time to time and it would be hard to mistake one song from each genre for the other. I'll break this experiment out into two parts:

1.  One experiment will be looking at metal songs vs. every other genre grouped together as "nonmetal"
2.  A second experiment will look at metal vs. country music

## Metal and Nonmetal

## Metal and Country

```{r}
metal.country <- songs %>% 
  filter(genre %in% c('metal', 'country'))
metal.country <- metal.country[,predictors]

metal.country$genre <- droplevels(metal.country$genre)

split1 <- initial_split(metal.country, prop = .7) # samples index

train1 <- training(split1)
test1 <- testing(split1)
```


Starting with logistic regression.

```{r}
cv.model.1 <- train(
  genre ~ .,
  data = train1,
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
)

```

Predicted classes and performance.

```{r}
preds <- predict(cv.model.1, test1)

confusionMatrix(
  data = relevel(preds, ref = "metal"),
  reference = relevel(test1$genre, ref = "metal")
)
```

Random forest example.

```{r}
rf1 <- ranger(
  genre ~ .,
  data = train1,
  mtry = 4,
  respect.unordered.factors = "order"
)

preds <- predict(rf1, data = test1)
table(test1$genre, preds$predictions)
(1152+1308)/nrow(test1)
```



```{r}


data <- metal.country[,num_predictors]
# metal_country_songs <- scale(metal_country_songs)   # note we scale here and conduct all subsequent clustering analysis on scaled data

# Find the principal components (I like the prcomp function but you could also use princomp)
pc <- prcomp(data, scale = TRUE)
# pc

plot(cumsum(pc$sdev^2/sum(pc$sdev^2)), main = 'Cumulative Variance Explained by Components', 
     ylab="Explained", xlab="Component")

# pc_plot1 <- autoplot(pc, data = metal.country, main = "Plot of Song Data in PC Space")
pc_plot2 <- autoplot(pc, data = metal.country, colour = "genre", main = "Plot of Song Data in PC Space", alpha = 0.5) 

# pc_plot1
pc_plot2
```


```{r, eval=FALSE}
components <- pc[["x"]]

components <- data.frame(components)

components$PC2 <- -components$PC2

components$PC3 <- -components$PC3

components = cbind(components, metal.country$genre)

fig <- plot_ly(components, x = ~PC1, y = ~PC2, z = ~PC3, color = ~metal.country$genre, colors = c('#636EFA','#EF553B','#00CC96') ) %>%

  add_markers(size = 12)



fig <- fig %>%

  layout(


    scene = list(bgcolor = "#e5ecf6")

)


fig
```


<!-- ```{r} -->

<!-- library(reticulate) -->

<!-- repl_python() -->

<!-- ``` -->

<!-- ```{python} -->

<!-- import pandas as pd -->

<!-- songs = pd.read_csv("H:\My Drive\Spotify_Project\genre_songs_8.csv", encoding = 'unicode_escape') -->

<!-- ``` -->

<!-- ```{python} -->

<!-- songs.cols() -->

<!-- ``` -->
